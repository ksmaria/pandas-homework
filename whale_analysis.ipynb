{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    " ---\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P TSX 60 Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "\n",
    "* `whale_returns.csv`: Contains returns of some famous \"whale\" investors' portfolios.\n",
    "\n",
    "* `algo_returns.csv`: Contains returns from the in-house trading algorithms from Harold's company.\n",
    "\n",
    "* `sp_tsx_history.csv`: Contains historical closing prices of the S&P TSX 60 Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whales_data = Path(\"Resources/whale_returns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading whale returns\n",
    "whales_df = pd.read_csv(whales_data, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sort whale returns DataFrame by Date Index\n",
    "whales_df.sort_index(inplace=True)\n",
    "whales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "whales_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "# Used the `dropna` function to drop whole records that have at least one null value\n",
    "whales_df.dropna(inplace=True)\n",
    "# Check no more nulls\n",
    "whales_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading algorithmic returns\n",
    "algo_data = Path(\"Resources/algo_returns.csv\")\n",
    "algo_df = pd.read_csv(algo_data, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sort algorithmic returns DateFrame by Date Index\n",
    "algo_df.sort_index(inplace=True)\n",
    "algo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls\n",
    "algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "algo_df.dropna(inplace=True)\n",
    "##algo_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P TSX 60 Returns\n",
    "\n",
    "Read the S&P TSX 60 historic closing prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading S&P TSX 60 Closing Prices\n",
    "sp60_data = Path(\"Resources/sp_tsx_history.csv\")\n",
    "sp60_df = pd.read_csv(sp60_data, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sort S&P TSX 60 DataFrame by Date Index\n",
    "sp60_df.sort_index(inplace=True)\n",
    "sp60_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "print(sp60_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types\n",
    "\n",
    "# Remove $ sign and , from sp60 Close values \n",
    "sp60_df['Close'] = sp60_df['Close'].str.replace('$', '')\n",
    "sp60_df['Close'] = sp60_df['Close'].str.replace(',', '')\n",
    "\n",
    "# Convert sp60 Close values to type float\n",
    "sp60_df['Close'] = sp60_df['Close'].astype(float)\n",
    "\n",
    "##print (sp60_df['Close'])\n",
    "print(sp60_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Daily Returns\n",
    "sp60_df['Daily Returns'] = sp60_df['Close'].pct_change()\n",
    "##sp60_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "##sp60_df.isnull().sum()\n",
    "sp60_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `Close` Column to be specific to this portfolio.\n",
    "# Renamed 'Daily Returns' Column to S&P TSX \n",
    "columns = [\"S&P Close\", \"S&P TSX\"]\n",
    "sp60_df.columns = columns\n",
    "sp60_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P TSX 60 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Column with closing prices, so we have only daily returns for \n",
    "# S&P TSX in the sp60_df\n",
    "sp60_df = sp60_df.drop(columns=[\"S&P Close\"], errors =\"ignore\")\n",
    "sp60_df.head()\n",
    "\n",
    "# Join Whale Returns, Algorithmic Returns, and the S&P TSX 60 Returns into a \n",
    "# single DataFrame with columns for each portfolio's returns.\n",
    "df_daily_returns = pd.concat([whales_df, algo_df, sp60_df], axis=\"columns\", join=\"inner\")\n",
    "df_daily_returns\n",
    "\n",
    "## Note for self can check index using .index\n",
    "## df_daily_returns.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Quantitative Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Anlysis\n",
    "\n",
    "#### Calculate and Plot the daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot daily returns of all portfolios\n",
    "df_daily_returns.plot(figsize=(20,10), title=\"Daily Returns of Whales, Algos and S&P TSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and Plot cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative returns of all portfolios\n",
    "cumulative_returns = (1 + df_daily_returns).cumprod() - 1\n",
    "cumulative_returns\n",
    "\n",
    "# Plot cumulative returns\n",
    "cumulative_returns.plot(figsize=(20,10), title=\"Cumulative Returns of Whales, Algos and S&P TSX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios.\n",
    "4. Determine which portfolios are riskier than the S&P TSX 60.\n",
    "5. Calculate the Annualized Standard Deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a box plot for each portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n",
    "df_daily_returns.plot.box(figsize=(20,10), title=\"Box Plot for Whales, Algos and S&P TSX\")\n",
    "\n",
    "##Note for self kept in comments for future reference\n",
    "##sns.set_style(\"white\")\n",
    "##sns.set(rc={\"figure.figsize\":(20, 10)})\n",
    "##sns.boxplot(x = None, y = None, hue = None, data=combined_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily standard deviations of all portfolios\n",
    "df_daily_returns.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which portfolios are riskier than the S&P TSX 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily standard deviation of S&P TSX 60\n",
    "risk_sNp = df_daily_returns['S&P TSX'].std()\n",
    "##print(risk_sNp)\n",
    "\n",
    "# Determine which portfolios are riskier than the S&P TSX 60\n",
    "df_daily_returns.std() > risk_sNp\n",
    "\n",
    "# Answer: Analysis Results show that all portfolios other than PAULSON & CO.INC. are\n",
    "# riskier than S&P 60 TSX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n",
    "volatility = df_daily_returns.std() * np.sqrt(252)\n",
    "volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Calculate and plot the rolling standard deviation for for all portfolios using a 21-day window.\n",
    "2. Calculate the correlation between each stock to determine which portfolios may mimick the S&P TSX 60.\n",
    "3. Choose one portfolio, then calculate and plot the 60-day rolling beta for it and the S&P TSX 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` for all portfolios with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the rolling standard deviation for all portfolios using a 21-day window\n",
    "rolling21_std = df_daily_returns.rolling(window=21).std()\n",
    "\n",
    "# Plot the rolling standard deviation\n",
    "rolling21_std.plot(figsize=(20,10), title=\"21-day rolling Std Deviations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation\n",
    "df_correlation = df_daily_returns.corr()\n",
    "\n",
    "# Display de correlation matrix\n",
    "df_correlation\n",
    "\n",
    "# Plot the correlation\n",
    "sns.heatmap(df_correlation, vmin=-1, vmax=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot Beta for a chosen portfolio and the S&P 60 TSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of a single portfolio. Covariance is calculated\n",
    "# for BERKSHIRE HATHAWAY INC against S&P 60 TSX for rolling window of 60 days\n",
    "\n",
    "covariance = df_daily_returns['BERKSHIRE HATHAWAY INC'].rolling(window=60).cov(df_daily_returns['S&P TSX'])\n",
    "#covariance.head(60)\n",
    "\n",
    "# Calculate variance of S&P TSX\n",
    "variance = df_daily_returns['S&P TSX'].rolling(window=60).var()\n",
    "##variance.head(65)\n",
    "\n",
    "# Computing beta\n",
    "berkshire_beta = covariance / variance\n",
    "##berkshire_beta\n",
    "\n",
    "# Plot beta trend\n",
    "berkshire_beta.plot(figsize=(20,10), title=\"Rolling 60-Day Beta of BERKSHIRE HATHAWAY INC\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics Challenge: Exponentially Weighted Average \n",
    "\n",
    "An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the [`ewm`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html) with a 21-day half-life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `ewm` to calculate the rolling window\n",
    "##df_daily_returns_ewm = df_daily_returns.ewm(halflife=21).mean() \n",
    "##df_daily_returns_ewm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. After all, if you could invest in one of two portfolios, and each offered the same 10% return, yet one offered lower risk, you'd take that one, right?\n",
    "\n",
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "sharpe_ratios = (df_daily_returns.mean() * 252) / (df_daily_returns.std() * np.sqrt(252))\n",
    "sharpe_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_ratios.plot.bar(figsize=(20,10), title=\"Sharpe Ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine whether the algorithmic strategies outperform both the market (S&P TSX 60) and the whales portfolios.\n",
    "\n",
    "Write your answer here! \n",
    "Algorithmic Strategies consist of Algo 1 and Algo 2.\n",
    "Based on the Sharpe Ratios - Algo 1 outperfromed the S&P TSX 60 and all the Whales. Algo 2 also outperforms S&P TSX 60 and 3 out of the 4 from Whales (Berkshire Hathaway in Whales is the only that Algo 1 did not outperform but came close behind)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Portfolio\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P TSX 60. \n",
    "\n",
    "1. Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock.\n",
    "2. Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock.\n",
    "3. Join your portfolio returns to the DataFrame that contains all of the portfolio returns.\n",
    "4. Re-run the performance and risk analysis with your portfolio to see how it compares to the others.\n",
    "5. Include correlation analysis to determine which stocks (if any) are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 1st stock\n",
    "msft_data = Path(\"Resources/msft_historical.csv\")\n",
    "msft_df = pd.read_csv(msft_data, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sort msft DataFrame by Date Index\n",
    "msft_df.sort_index(inplace=True)\n",
    "msft_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 2nd stock\n",
    "aapl_data = Path(\"Resources/aapl_historical.csv\")\n",
    "aapl_df = pd.read_csv(aapl_data, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sort aapl DataFrame by Date Index\n",
    "aapl_df.sort_index(inplace=True)\n",
    "aapl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 3rd stock\n",
    "amzn_data = Path(\"Resources/amzn_historical.csv\")\n",
    "amzn_df = pd.read_csv(amzn_data, index_col=\"Date\", infer_datetime_format=True, parse_dates=True)\n",
    "\n",
    "# Sort L DataFrame by Date Index\n",
    "amzn_df.sort_index(inplace=True)\n",
    "amzn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all stocks in a single DataFrame\n",
    "\n",
    "# Prepare the dataframes before concatenating\n",
    "# Rename 'Symbol' & `Close` Column to be specific to portfolio.\n",
    "columns_msft = [\"MSFT Symbol\", \"MSFT Close\"]\n",
    "msft_df.columns = columns_msft\n",
    "##msft_df.head()\n",
    "\n",
    "columns_aapl = [\"AAPL Symbol\", \"AAPL Close\"]\n",
    "aapl_df.columns = columns_aapl\n",
    "##aapl__df.head()\n",
    "\n",
    "columns_amzn = [\"AMZN Symbol\", \"AMZN Close\"]\n",
    "amzn_df.columns = columns_amzn\n",
    "##amzn__df.head()\n",
    "\n",
    "# Drop Symbols Column, so we have only closing columns for all 3 dataframes \n",
    "msft_df = msft_df.drop(columns=[\"MSFT Symbol\"], errors =\"ignore\")\n",
    "aapl_df = aapl_df.drop(columns=[\"AAPL Symbol\"], errors =\"ignore\")\n",
    "amzn_df = amzn_df.drop(columns=[\"AMZN Symbol\"], errors =\"ignore\")\n",
    "\n",
    "# Concatenate the 3 stock dataframes into one portfolio df\n",
    "df_portfolio = pd.concat([msft_df, aapl_df, amzn_df], axis=\"columns\", join=\"inner\")\n",
    "df_portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Date index\n",
    "df_portfolio = df_portfolio.reset_index()\n",
    "df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize portfolio data by having a column per symbol\n",
    "# Renamed 'Close' Columns to be symbols \n",
    "columns = [\"Date\", \"MSFT\", \"AAPL\", \"AMZN\"]\n",
    "df_portfolio.columns = columns\n",
    "\n",
    "# Set Index to Date and Sort\n",
    "df_portfolio.set_index(\"Date\", drop=True, inplace=True)\n",
    "df_portfolio.sort_index(inplace=True)\n",
    "\n",
    "df_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "df_portfolio_returns = df_portfolio.pct_change()\n",
    "df_portfolio_returns\n",
    "\n",
    "# Count nulls\n",
    "df_portfolio_returns.isnull().sum()\n",
    "\n",
    "# Drop NAs\n",
    "df_portfolio_returns.dropna(inplace=True)\n",
    "##df_portfolio_returns.isnull().sum()\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_returns.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Calculate portfolio return\n",
    "df_portfolio_weighted = df_portfolio_returns.dot(weights)\n",
    "\n",
    "# Display sample data\n",
    "df_portfolio_weighted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join your returns DataFrame to the original returns DataFrame\n",
    "\n",
    "df_all_returns = pd.concat([df_daily_returns, df_portfolio_weighted], axis=\"columns\", join=\"inner\")\n",
    "df_all_returns\n",
    "\n",
    "# Rename Columns\n",
    "columns_portfolio = [\"SOROS FUND MANAGEMENT LLC\", \"PAULSON & CO.INC.\", \"TIGER GLOBAL MANAGEMENT LLC\",\n",
    "                     \"BERKSHIRE HATHAWAY INC\", \"Algo 1\", \"Algo 2\", \"S&P TSX\", \"Custom\"]\n",
    "df_all_returns.columns = columns_portfolio\n",
    "\n",
    "df_all_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where return data exists for all the stocks (drop NaNs)\n",
    "df_all_returns.isnull().sum()\n",
    "df_all_returns.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized `std`\n",
    "volatility = df_all_returns.std() * np.sqrt(252)\n",
    "volatility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling standard deviation\n",
    "# for all portfolios for 21-day rolling window\n",
    "all_rolling21_std = df_all_returns.rolling(window=21).std()\n",
    "\n",
    "# Plot the rolling standard deviation\n",
    "all_rolling21_std.plot(figsize=(20,10), title=\"21-day rolling Std Deviations\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the correlation\n",
    "df_all_correlation = df_all_returns.corr()\n",
    "sns.heatmap(df_all_correlation, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot the 60-day Rolling Beta for Your Portfolio compared to the S&P 60 TSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot Beta\n",
    "covariance_custom = df_all_returns['Custom'].rolling(window=60).cov(df_all_returns['S&P TSX'])\n",
    "\n",
    "# Calculate variance of S&P TSX\n",
    "variance_custom = df_all_returns['S&P TSX'].rolling(window=60).var()\n",
    "\n",
    "# Computing beta\n",
    "custom_beta = covariance_custom / variance_custom\n",
    "\n",
    "# Plot beta trend\n",
    "custom_beta.plot(figsize=(20,10), title=\"Rolling 60-Day Beta of CUSTOM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Annualized Sharpe Ratios\n",
    "sharpe_ratios_custom = (df_all_returns.mean() * 252) / (df_all_returns.std() * np.sqrt(252))\n",
    "sharpe_ratios_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_ratios_custom.plot.bar(figsize=(20,10), title=\"Sharpe Ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does your portfolio do?\n",
    "\n",
    "Write your answer here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: For custom portfolio I understood the comment \"at last one year\" as at LEAST one year\n",
    "#so used google finance to get data for MSFT, AAPL and AMZN from 01 JAN 2019 till date\n",
    "#=GOOGLEFINANCE(\"MSFT\", \"price\", \"1/1/2019\", \"12/31/2021\", \"DAILY\") and saved to .csv similar to OTEX\n",
    "\n",
    "##The perfomance and risk analysis done above shows that my custom portfolio is ??\n",
    "## The custom portfolio as per my risk analysis falls in the highest risk based on\n",
    "## Annalized standard deviation\n",
    "## My custom portfolio has highest positive correlation with Berkshire Hathway and\n",
    "## highest negative correlation with Algo 1\n",
    "## Custom Portfolio has a good sharpe ration 3.5 but there are other stocks outperforming\n",
    "##it using this measurement\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
